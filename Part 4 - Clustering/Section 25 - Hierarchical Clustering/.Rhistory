x <- c(-0.5, 0, 1, 1, 1.5)
y <- c(0, 0,2,0,0)
plot(x, y, lwd = 3, frame = FALSE, type = "1")
plot(x, y, lwd = 3, frame = FALSE, type = "l")
pbeta(0.75,2,1)
exit()
exit
quit()
print("Hellow World")
setwd("~/Google Drive/learn-to-learn/machine-learning/udemy/Machine Learning A-Z/Part 4 - Clustering/Section 25 - Hierarchical Clustering")
dataset = read.csv('Mall_Customers.csv')
X = dataset[4:5]
View(X)
View(dataset)
dendrogram = hclust(dist(X, method = 'euclidian'), method = 'ward.D')
plot(dendrogram,
main = paste('Dendrogram'),
xlab = 'Customers',
ylab = 'Euclidian distances')
hc = hclust(dist(X, mehtod = 'euclidian'), method = 'ward.D')
hc = hclust(dist(X, method = 'euclidian'), method = 'ward.D')
y_hc = cutree(hc, 5)
hc
y_hc
library(cluster)
clusplot(y_hc,
kmeans$cluster,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2,
plotchar = FALSE,
span = TRUE,
main = paste('Clusters of customers'),
xlab = 'Annual Income',
ylab = 'Spending Score')
clusplot(X,
kmeans$cluster,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2,
plotchar = FALSE,
span = TRUE,
main = paste('Clusters of customers'),
xlab = 'Annual Income',
ylab = 'Spending Score')
clusplot(X,
y_hc,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2,
plotchar = FALSE,
span = TRUE,
main = paste('Clusters of customers'),
xlab = 'Annual Income',
ylab = 'Spending Score')
